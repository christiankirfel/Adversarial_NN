{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Set up environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.1 Select Theano as backend for Keras\n",
    "Tensorflow also works with ATLBONNTW-81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/local/bin python3\n",
    "\n",
    "from os import environ\n",
    "environ['KERAS_BACKEND'] = 'theano'\n",
    "#environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "# Set architecture of system (AVX instruction set is not supported on SWAN)\n",
    "environ['THEANO_FLAGS'] = 'gcc.cxxflags=-march=corei7'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1.2 Read variables and options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# # Process command line arguments\n",
    "# if not len(sys.argv)==2:\n",
    "#     print('Usage: python AdverNet.py <region>')\n",
    "#     sys.exit()\n",
    "# region = str(sys.argv[1])\n",
    "region = \"1j1b\"\n",
    "# region = \"tZ\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pt_sys_Lep1Lep2METJet1', 'SumET', 'pt_sys_Lep1Lep2', 'Centrality_Lep1Lep2', 'massTrans_Jet1MET', 'DeltaR_Lep1_Jet1', 'mass_Lep1Jet1', 'eta_Lep1Lep2METJet1', 'EoM_Lep2Jet1', 'pt_sys_Lep1Lep2Jet1', 'y_Lep2', 'mass_Jet1'] EventWeight\n",
      "{'': [], 'bins': '10', 'File': 'test2', 'SignalTree': ['wt_DR_nominal', 'wt_DS'], 'xlo': '0', 'Adresult': 'ANN_D', 'BackgroundName': 'tt', 'BackgroundTree': ['tt_nominal', 'tt_radHi'], 'PreTrainEpochs': '20', 'xhi': '1', 'SimpleTrainEpochs': '20', 'OutFile': 'ann', 'Output': 'bak-modelexp', 'DrawNorm': '0', 'Iterations': '99', 'EventWeight': 'EventWeight', 'yScale': '1.5', 'AllTrees': ['data_nominal', 'wt_DR_nominal', 'wt_DR_EG_RESOLUTION_ALL__1down', 'wt_DR_EG_RESOLUTION_ALL__1up', 'wt_DR_EG_SCALE_ALL__1down', 'wt_DR_EG_SCALE_ALL__1up', 'wt_DR_JET_21NP_JET_BJES_Response__1down', 'wt_DR_JET_21NP_JET_BJES_Response__1up', 'wt_DR_JET_21NP_JET_EffectiveNP_1__1down', 'wt_DR_JET_21NP_JET_EffectiveNP_1__1up', 'wt_DR_JET_21NP_JET_EffectiveNP_2__1down', 'wt_DR_JET_21NP_JET_EffectiveNP_2__1up', 'wt_DR_JET_21NP_JET_EffectiveNP_3__1down', 'wt_DR_JET_21NP_JET_EffectiveNP_3__1up', 'wt_DR_JET_21NP_JET_EffectiveNP_4__1down', 'wt_DR_JET_21NP_JET_EffectiveNP_4__1up', 'wt_DR_JET_21NP_JET_EffectiveNP_5__1down', 'wt_DR_JET_21NP_JET_EffectiveNP_5__1up', 'wt_DR_JET_21NP_JET_EffectiveNP_6__1down', 'wt_DR_JET_21NP_JET_EffectiveNP_6__1up', 'wt_DR_JET_21NP_JET_EffectiveNP_7__1down', 'wt_DR_JET_21NP_JET_EffectiveNP_7__1up', 'wt_DR_JET_21NP_JET_EffectiveNP_8restTerm__1down', 'wt_DR_JET_21NP_JET_EffectiveNP_8restTerm__1up', 'wt_DR_JET_21NP_JET_EtaIntercalibration_Modelling__1down', 'wt_DR_JET_21NP_JET_EtaIntercalibration_Modelling__1up', 'wt_DR_JET_21NP_JET_EtaIntercalibration_NonClosure__1down', 'wt_DR_JET_21NP_JET_EtaIntercalibration_NonClosure__1up', 'wt_DR_JET_21NP_JET_EtaIntercalibration_TotalStat__1down', 'wt_DR_JET_21NP_JET_EtaIntercalibration_TotalStat__1up', 'wt_DR_JET_21NP_JET_Flavor_Composition__1down', 'wt_DR_JET_21NP_JET_Flavor_Composition__1up', 'wt_DR_JET_21NP_JET_Flavor_Response__1down', 'wt_DR_JET_21NP_JET_Flavor_Response__1up', 'wt_DR_JET_21NP_JET_Pileup_OffsetMu__1down', 'wt_DR_JET_21NP_JET_Pileup_OffsetMu__1up', 'wt_DR_JET_21NP_JET_Pileup_OffsetNPV__1down', 'wt_DR_JET_21NP_JET_Pileup_OffsetNPV__1up', 'wt_DR_JET_21NP_JET_Pileup_PtTerm__1down', 'wt_DR_JET_21NP_JET_Pileup_PtTerm__1up', 'wt_DR_JET_21NP_JET_Pileup_RhoTopology__1down', 'wt_DR_JET_21NP_JET_Pileup_RhoTopology__1up', 'wt_DR_JET_21NP_JET_PunchThrough_MC15__1down', 'wt_DR_JET_21NP_JET_PunchThrough_MC15__1up', 'wt_DR_JET_21NP_JET_SingleParticle_HighPt__1down', 'wt_DR_JET_21NP_JET_SingleParticle_HighPt__1up', 'wt_DR_JET_JER_SINGLE_NP__1up', 'wt_DR_MET_SoftTrk_ResoPara', 'wt_DR_MET_SoftTrk_ResoPerp', 'wt_DR_MET_SoftTrk_ScaleDown', 'wt_DR_MET_SoftTrk_ScaleUp', 'wt_DR_MUON_ID__1down', 'wt_DR_MUON_ID__1up', 'wt_DR_MUON_MS__1down', 'wt_DR_MUON_MS__1up', 'wt_DR_MUON_SAGITTA_RESBIAS__1down', 'wt_DR_MUON_SAGITTA_RESBIAS__1up', 'wt_DR_MUON_SAGITTA_RHO__1down', 'wt_DR_MUON_SAGITTA_RHO__1up', 'wt_DR_MUON_SCALE__1down', 'wt_DR_MUON_SCALE__1up', 'wt_DS', 'wt_af2_ME', 'wt_af2_PS', 'wt_af2_nominal', 'wt_af2_radHi', 'wt_af2_radLo', 'tt_nominal', 'tt_EG_RESOLUTION_ALL__1down', 'tt_EG_RESOLUTION_ALL__1up', 'tt_EG_SCALE_ALL__1down', 'tt_EG_SCALE_ALL__1up', 'tt_JET_21NP_JET_BJES_Response__1down', 'tt_JET_21NP_JET_BJES_Response__1up', 'tt_JET_21NP_JET_EffectiveNP_1__1down', 'tt_JET_21NP_JET_EffectiveNP_1__1up', 'tt_JET_21NP_JET_EffectiveNP_2__1down', 'tt_JET_21NP_JET_EffectiveNP_2__1up', 'tt_JET_21NP_JET_EffectiveNP_3__1down', 'tt_JET_21NP_JET_EffectiveNP_3__1up', 'tt_JET_21NP_JET_EffectiveNP_4__1down', 'tt_JET_21NP_JET_EffectiveNP_4__1up', 'tt_JET_21NP_JET_EffectiveNP_5__1down', 'tt_JET_21NP_JET_EffectiveNP_5__1up', 'tt_JET_21NP_JET_EffectiveNP_6__1down', 'tt_JET_21NP_JET_EffectiveNP_6__1up', 'tt_JET_21NP_JET_EffectiveNP_7__1down', 'tt_JET_21NP_JET_EffectiveNP_7__1up', 'tt_JET_21NP_JET_EffectiveNP_8restTerm__1down', 'tt_JET_21NP_JET_EffectiveNP_8restTerm__1up', 'tt_JET_21NP_JET_EtaIntercalibration_Modelling__1down', 'tt_JET_21NP_JET_EtaIntercalibration_Modelling__1up', 'tt_JET_21NP_JET_EtaIntercalibration_NonClosure__1down', 'tt_JET_21NP_JET_EtaIntercalibration_NonClosure__1up', 'tt_JET_21NP_JET_EtaIntercalibration_TotalStat__1down', 'tt_JET_21NP_JET_EtaIntercalibration_TotalStat__1up', 'tt_JET_21NP_JET_Flavor_Composition__1down', 'tt_JET_21NP_JET_Flavor_Composition__1up', 'tt_JET_21NP_JET_Flavor_Response__1down', 'tt_JET_21NP_JET_Flavor_Response__1up', 'tt_JET_21NP_JET_Pileup_OffsetMu__1down', 'tt_JET_21NP_JET_Pileup_OffsetMu__1up', 'tt_JET_21NP_JET_Pileup_OffsetNPV__1down', 'tt_JET_21NP_JET_Pileup_OffsetNPV__1up', 'tt_JET_21NP_JET_Pileup_PtTerm__1down', 'tt_JET_21NP_JET_Pileup_PtTerm__1up', 'tt_JET_21NP_JET_Pileup_RhoTopology__1down', 'tt_JET_21NP_JET_Pileup_RhoTopology__1up', 'tt_JET_21NP_JET_PunchThrough_MC15__1down', 'tt_JET_21NP_JET_PunchThrough_MC15__1up', 'tt_JET_21NP_JET_SingleParticle_HighPt__1down', 'tt_JET_21NP_JET_SingleParticle_HighPt__1up', 'tt_JET_JER_SINGLE_NP__1up', 'tt_MET_SoftTrk_ResoPara', 'tt_MET_SoftTrk_ResoPerp', 'tt_MET_SoftTrk_ScaleDown', 'tt_MET_SoftTrk_ScaleUp', 'tt_MUON_ID__1down', 'tt_MUON_ID__1up', 'tt_MUON_MS__1down', 'tt_MUON_MS__1up', 'tt_MUON_SAGITTA_RESBIAS__1down', 'tt_MUON_SAGITTA_RESBIAS__1up', 'tt_MUON_SAGITTA_RHO__1down', 'tt_MUON_SAGITTA_RHO__1up', 'tt_MUON_SCALE__1down', 'tt_MUON_SCALE__1up', 'tt_af2_ME', 'tt_af2_PS', 'tt_af2_nominal', 'tt_radHi', 'tt_radLo'], 'UseWeight': '1', 'AdTrainEpochs': '5', 'Pkl': 'train_events', 'SignalName': 'tW', 'TrainFraction': '0.6'}\n"
     ]
    }
   ],
   "source": [
    "with open('Variables_'+region+'.txt','r') as varfile:\n",
    "    variableList = varfile.read().splitlines() \n",
    "\n",
    "def ReadOptions(region):\n",
    "    with open('KerasOptions_'+region+'.txt','r') as infile:\n",
    "        optionsList = infile.read().splitlines()\n",
    "    OptionDict = dict()\n",
    "    for options in optionsList:\n",
    "        if options.startswith('#'): continue\n",
    "        templist = options.split(' ')\n",
    "        if len(templist) == 2:\n",
    "            OptionDict[templist[0]] = templist[1]\n",
    "        else:\n",
    "            OptionDict[templist[0]] = templist[1:]\n",
    "    return OptionDict\n",
    "\n",
    "Options = ReadOptions(region)\n",
    "\n",
    "print (variableList, Options['EventWeight'])\n",
    "print (Options)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2. Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.1 Read ROOT file\n",
    "Two ways to read data:\n",
    "https://indico.fnal.gov/event/13497/session/1/material/slides/0?contribId=47 page 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'root_numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e3c684277981>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mroot_numpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroot2array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree2array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mROOT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Get TTree from pyROOT then convert to numpy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'root_numpy'"
     ]
    }
   ],
   "source": [
    "from root_numpy import root2array, tree2array\n",
    "import ROOT\n",
    "from numpy import *\n",
    "\n",
    "#Get TTree from pyROOT then convert to numpy array\n",
    "file = ROOT.TFile('data/'+str(Options['File'])+'_'+region+'_nominal.root')\n",
    "file.ls()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "''' *array* is [eventVariables, EventWeight]; *event* is [eventVariables]; *weight* is [EventWeight]'''\n",
    "tree__signal = []\n",
    "tree__background = []\n",
    "event__signal = []\n",
    "event__background = []\n",
    "weight__signal = []\n",
    "weight__background = []\n",
    "array__signal = []\n",
    "array__background = []\n",
    "\n",
    "name__signal = Options['SignalTree']\n",
    "name__background = Options['BackgroundTree']\n",
    "\n",
    "print name__signal\n",
    "for name in name__signal:\n",
    "    print 'name', name\n",
    "    tree__signal.append(file.Get(name))\n",
    "    event__signal.append(tree2array(tree__signal[-1], branches=variableList, selection='1'))\n",
    "    weight__signal.append(tree2array(tree__signal[-1], branches=[ Options['EventWeight'] ], selection='1'))\n",
    "#     weight__signal.append(tree2array(tree__signal[-1], branches=\"EventWeight\", selection='1'))\n",
    "    array__signal.append([list(elem) for elem in zip(event__signal[-1], weight__signal[-1])])\n",
    "for name in name__background:\n",
    "    tree__background.append(file.Get(name))\n",
    "    event__background.append(tree2array(tree__background[-1], branches=variableList, selection='1'))\n",
    "    weight__background.append(tree2array(tree__background[-1], branches=[ Options['EventWeight'] ], selection='1'))\n",
    "    array__background.append([list(elem) for elem in zip(event__background[-1], weight__background[-1])])\n",
    "\n",
    "if bool(int(Options['UseWeight'])) is False:\n",
    "    for weight in weight__signal:\n",
    "        weight[:] = 1\n",
    "    for weight in weight__background:\n",
    "        weight[:] = 1\n",
    "    print ('EventWeight set to 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.2 Split into training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Construct **train\\_\\_sample\\_nominal**, **test\\_\\_sample\\_nominal** \n",
    "and their coresponding score **targettrain\\_\\_sample\\_nominal**\n",
    "**targettest\\_\\_sample\\_nominal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "'''using Options['TrainFraction'] to control fractions of training and test samples'''\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "def weight_ratio(weight__signal, weight__background):\n",
    "    total_weight__signal = total_weight__background = 0\n",
    "    for weight in weight__signal:\n",
    "        total_weight__signal += sum(j[0] for j in [list(i) for i in weight])\n",
    "    for weight in weight__background:\n",
    "        total_weight__background += sum(j[0] for j in [list(i) for i in weight])\n",
    "    return total_weight__signal / total_weight__background\n",
    "\n",
    "ratiotWtt = weight_ratio(weight__signal, weight__background)\n",
    "# ratiotWtt = sum(j[0] for j in [list(i) for i in weight__signal[0]]) / sum(j[0] for j in [list(i) for i in weight__background[0]])\n",
    "\n",
    "train_array__signal = []\n",
    "test_array__signal = []\n",
    "train_array__background = []\n",
    "test_array__background = []\n",
    "\n",
    "''' *array* is [eventVariables, EventWeight]; *event* is [eventVariables]; *weight* is [EventWeight] '''\n",
    "''' Construct train and test for wt_DR, tt, wt_DS '''\n",
    "for array in array__signal:\n",
    "    train_array, test_array = train_test_split(array, train_size=float(Options['TrainFraction']), test_size=1-float(Options['TrainFraction']), random_state = 1)\n",
    "    train_array__signal.append(deepcopy(train_array))\n",
    "    test_array__signal.append(deepcopy(test_array))\n",
    "\n",
    "for array in array__background:\n",
    "    train_array, test_array = train_test_split(array, train_size=float(Options['TrainFraction']), test_size=1-float(Options['TrainFraction']), random_state = 1)\n",
    "    train_array__background.append(deepcopy(train_array))\n",
    "    test_array__background.append(deepcopy(test_array))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "train_event__signal = []\n",
    "train_weight__signal = []\n",
    "train_event__background = []\n",
    "train_weight__background = []\n",
    "test_event__signal = []\n",
    "test_weight__signal = []\n",
    "test_event__background = []\n",
    "test_weight__background = []\n",
    "\n",
    "for train_array in train_array__signal:\n",
    "    train_event__signal.append([list(i[0]) for i in train_array])\n",
    "    train_weight__signal.append([j[0]/ratiotWtt for j in [list(i[1]) for i in train_array]])\n",
    "\n",
    "for train_array in train_array__background:\n",
    "    train_event__background.append([list(i[0]) for i in train_array])\n",
    "    train_weight__background.append([j[0] for j in [list(i[1]) for i in train_array]])\n",
    "\n",
    "for test_array in test_array__signal:\n",
    "    test_event__signal.append([list(i[0]) for i in test_array])\n",
    "    test_weight__signal.append([j[0]/ratiotWtt for j in [list(i[1]) for i in test_array]])\n",
    "\n",
    "for test_array in test_array__background:\n",
    "    test_event__background.append([list(i[0]) for i in test_array])\n",
    "    test_weight__background.append([j[0] for j in [list(i[1]) for i in test_array]])\n",
    "\n",
    "\n",
    "''' Construct target for train and test for wt_DR, tt, wt_DS\n",
    "    wt = 1; tt = 0 '''\n",
    "train_target__signal = []\n",
    "test_target__signal = []\n",
    "train_target__background = []\n",
    "test_target__background = []\n",
    "\n",
    "for train_array in train_array__signal:\n",
    "    train_target__signal.append(np.arange(len(train_array)))\n",
    "    train_target__signal[-1][:] = 1\n",
    "for test_array in test_array__signal:\n",
    "    test_target__signal.append(np.arange(len(test_array)))\n",
    "    test_target__signal[-1][:] = 1\n",
    "for train_array in train_array__background:\n",
    "    train_target__background.append(np.arange(len(train_array)))\n",
    "    train_target__background[-1][:] = 0\n",
    "for test_array in test_array__background:\n",
    "    test_target__background.append(np.arange(len(test_array)))\n",
    "    test_target__background[-1][:] = 0\n",
    "\n",
    "\n",
    "''' Construct systematics for train and test for wt_DR, tt, wt_DS\n",
    "    wt_DR = tt = 0; wt_DS = 1 '''\n",
    "train_systematics__signal = []\n",
    "test_systematics__signal = []\n",
    "train_systematics__background = []\n",
    "test_systematics__background = []\n",
    "\n",
    "for train_array in train_array__signal:\n",
    "    train_systematics__signal.append(np.arange(len(train_array)))\n",
    "    train_systematics__signal[-1][:] = 0 if len(train_systematics__signal)==1 else 1\n",
    "for test_array in test_array__signal:\n",
    "    test_systematics__signal.append(np.arange(len(test_array)))\n",
    "    test_systematics__signal[-1][:] = 0 if len(test_systematics__signal)==1 else 1\n",
    "for train_array in train_array__background:\n",
    "    train_systematics__background.append(np.arange(len(train_array)))\n",
    "    train_systematics__background[-1][:] = 0 if len(train_systematics__background)==1 else 1\n",
    "for test_array in test_array__background:\n",
    "    test_systematics__background.append(np.arange(len(test_array)))\n",
    "    test_systematics__background[-1][:] = 0 if len(test_systematics__background)==1 else 1\n",
    "\n",
    "\n",
    "for i in range(len(array__signal)):\n",
    "    assert (len(train_array__signal[i])+len(test_array__signal[i]) == len(array__signal[i]))\n",
    "for i in range(len(array__background)):\n",
    "    assert (len(train_array__background[i])+len(test_array__background[i]) == len(array__background[i]))\n",
    "\n",
    "\n",
    "print ('Training sample wt_DR_nominal: ', len(train_event__signal[0]), '\\n',\n",
    "       '                tt_nominal:   ', len(train_event__background[0]))\n",
    "for i in range(1, len(train_event__signal)):\n",
    "    print ('                 wt syst', i, ':   ', len(train_event__signal[i]))\n",
    "for i in range(1, len(train_event__background)):\n",
    "    print ('                 tt syst', i, ':   ', len(train_event__background[i]))\n",
    "print('              total nominal:   ', len(train_event__signal[0]) + len(train_event__background[0]))\n",
    "print ('Test sample wt_DR_nominal: ', len(test_event__signal[0]), '\\n',\n",
    "       '           tt_nominal:    ', len(test_event__background[0]))\n",
    "for i in range(1, len(test_event__signal)):\n",
    "    print('            wt syst', i, ':    ', len(test_event__signal[i]))\n",
    "for i in range(1, len(test_event__background)):\n",
    "    print('            tt_syst', i, ':    ', len(test_event__background[i]))\n",
    "print('         total nominal:    ', len(test_event__signal[0]) + len(test_event__background[0]))\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Merge signal and backgrounds to **train(test)\\_\\_event(weight)\\_\\_nominal** \n",
    "and their coresponding score **targettrain(test)\\_\\_nominal**\n",
    "**systematicstrain(test)\\_\\_nominal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "''' Construct sample, EventWeight, target, systematics of train and test\n",
    "    mixing parts of wt_DR, tt, wt_DS '''\n",
    "\n",
    "train_event__list = []\n",
    "for train_event in train_event__signal:\n",
    "    train_event__list.append(train_event)\n",
    "for train_event in train_event__background:\n",
    "    train_event__list.append(train_event)\n",
    "train_event = np.vstack(train_event__list)\n",
    "\n",
    "test_event__list = []\n",
    "for test_event in test_event__signal:\n",
    "    test_event__list.append(test_event)\n",
    "for test_event in test_event__background:\n",
    "    test_event__list.append(test_event)\n",
    "test_event = np.vstack(test_event__list)\n",
    "\n",
    "train_weight__list = []\n",
    "for train_weight in train_weight__signal:\n",
    "    train_weight__list.append(train_weight)\n",
    "for train_weight in train_weight__background:\n",
    "    train_weight__list.append(train_weight)\n",
    "train_weight = np.concatenate(train_weight__list)\n",
    "\n",
    "test_weight__list = []\n",
    "for test_weight in test_weight__signal:\n",
    "    test_weight__list.append(test_weight)\n",
    "for test_weight in test_weight__background:\n",
    "    test_weight__list.append(test_weight)\n",
    "test_weight = np.concatenate(test_weight__list)\n",
    "\n",
    "train_target__list = []\n",
    "for train_target in train_target__signal:\n",
    "    train_target__list.append(train_target)\n",
    "for train_target in train_target__background:\n",
    "    train_target__list.append(train_target)\n",
    "train_target = np.concatenate(train_target__list)\n",
    "\n",
    "test_target__list = []\n",
    "for test_target in test_target__signal:\n",
    "    test_target__list.append(test_target)\n",
    "for test_target in test_target__background:\n",
    "    test_target__list.append(test_target)\n",
    "test_target = np.concatenate(test_target__list)\n",
    "\n",
    "\n",
    "train_systematics__list = []\n",
    "for train_systematics in train_systematics__signal:\n",
    "    train_systematics__list.append(train_systematics)\n",
    "for train_systematics in train_systematics__background:\n",
    "    train_systematics__list.append(train_systematics)\n",
    "train_systematics = np.concatenate(train_systematics__list)\n",
    "\n",
    "test_systematics__list = []\n",
    "for test_systematics in test_systematics__signal:\n",
    "    test_systematics__list.append(test_systematics)\n",
    "for test_systematics in test_systematics__background:\n",
    "    test_systematics__list.append(test_systematics)\n",
    "test_systematics = np.concatenate(test_systematics__list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "''' Data conversion of sample '''\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_event_transfered = scaler.fit_transform(train_event)\n",
    "\n",
    "#store the content\n",
    "with open(outfolder + Options['Pkl'] + '.pkl', 'wb') as handle:\n",
    "    pickle.dump(scaler, handle)\n",
    "#load the content\n",
    "scaler = pickle.load(outfolder + open(Options['Pkl']+'.pkl', 'rb' ) )\n",
    "\n",
    "test_event_transfered = scaler.transform(test_event)\n",
    "\n",
    "assert (train_event_transfered.shape[1] == len(variableList))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3. Simple networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 3.1 Build networks by Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "# 3 hiddend layers\n",
    "simple_inputs = Input(shape=(train_event_transfered.shape[1],), name='Net_input')\n",
    "simple_Dx = Dense(32, activation=\"relu\", name='Net_layer1')(simple_inputs)\n",
    "simple_Dx = Dense(32, activation=\"relu\", name='Net_layer2')(simple_Dx)\n",
    "simple_Dx = Dense(32, activation=\"relu\", name='Net_layer3')(simple_Dx)\n",
    "simple_Dx = Dense(32, activation=\"relu\", name='Net_layer4')(simple_Dx)\n",
    "simple_Dx = Dense(32, activation=\"relu\", name='Net_layer5')(simple_Dx)\n",
    "simple_Dx = Dense(1, activation=\"sigmoid\", name='Net_output')(simple_Dx)\n",
    "simple_D = Model(inputs=[simple_inputs], outputs=[simple_Dx], name='Net_model')\n",
    "simple_D.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "simple_D.summary()\n",
    "plot_model(simple_D, to_file='png/simple_D.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 3.2 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "''' Train on train_event with target train_target, using train_weight as EventWeight '''\n",
    "simple_D.fit(train_event_transfered, train_target, sample_weight=train_weight, epochs=int(Options['SimpleTrainEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 3.3 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "''' Apply training results to test sample; and training sample for checking '''\n",
    "from sklearn.metrics import roc_auc_score\n",
    "predicttest__simple_D = simple_D.predict(test_event_transfered)\n",
    "predicttrain__simple_D = simple_D.predict(train_event_transfered)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 3.4 Calculate and plot ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "print('Traing ROC: ', roc_auc_score(train_target, predicttrain__simple_D))\n",
    "print('Test ROC:   ', roc_auc_score(test_target, predicttest__simple_D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "''' Plot ROC '''\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train__false_positive_rate, train__true_positive_rate, train__thresholds = roc_curve(train_target, predicttrain__simple_D)\n",
    "test__false_positive_rate, test__true_positive_rate, test__thresholds = roc_curve(test_target, predicttest__simple_D)\n",
    "train__roc_auc = auc(train__false_positive_rate, train__true_positive_rate)\n",
    "test__roc_auc = auc(test__false_positive_rate, test__true_positive_rate)\n",
    "\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(train__false_positive_rate, train__true_positive_rate, 'g--', label='Train AUC = %0.2f'% train__roc_auc)\n",
    "plt.plot(test__false_positive_rate, test__true_positive_rate, 'b', label='Test AUC = %0.2f'% test__roc_auc)\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.,1.])\n",
    "plt.ylim([-0.,1.])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "plt.gcf().clear()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 3.5 Plot traing and test distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "''' Plot NN output '''\n",
    "xlo, xhi, bins = float(Options['xlo']), float(Options['xhi']), int(Options['bins'])\n",
    "SignalName, BckgrdName = Options['SignalName'], Options['BackgroundName']\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(predicttrain__simple_D[train_target == 1], range=[xlo,xhi], bins=bins, histtype=\"step\", normed=0, label=SignalName+' training')\n",
    "plt.hist(predicttrain__simple_D[train_target == 0], range=[xlo,xhi], bins=bins, histtype=\"step\", normed=0, label=BckgrdName+' training')\n",
    "plt.hist(predicttest__simple_D[test_target == 1],   range=[xlo,xhi], bins=bins, histtype=\"step\", normed=0, label=SignalName+' test', linestyle='dashed')\n",
    "plt.hist(predicttest__simple_D[test_target == 0],   range=[xlo,xhi], bins=bins, histtype=\"step\", normed=0, label=BckgrdName+' test', linestyle='dashed')\n",
    "plt.ylim(0, plt.gca().get_ylim()[1] * float(Options['yScale']))\n",
    "plt.legend()\n",
    "plt.xlabel('Simple_D response', horizontalalignment='left', fontsize='large')\n",
    "plt.title('Absolute')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(predicttrain__simple_D[train_target == 1], range=[xlo,xhi], bins=bins, histtype=\"step\", normed=1, label=SignalName+' training')\n",
    "plt.hist(predicttrain__simple_D[train_target == 0], range=[xlo,xhi], bins=bins, histtype=\"step\", normed=1, label=BckgrdName+' training')\n",
    "plt.hist(predicttest__simple_D[test_target == 1],   range=[xlo,xhi], bins=bins, histtype=\"step\", normed=1, label=SignalName+' test', linestyle='dashed')\n",
    "plt.hist(predicttest__simple_D[test_target == 0],   range=[xlo,xhi], bins=bins, histtype=\"step\", normed=1, label=BckgrdName+' test', linestyle='dashed')\n",
    "plt.ylim(0, plt.gca().get_ylim()[1] * float(Options['yScale']))\n",
    "plt.legend()\n",
    "plt.xlabel('Simple_D response', horizontalalignment='left', fontsize='large')\n",
    "plt.title('Normalised')\n",
    "\n",
    "plt.show()\n",
    "plt.gcf().clear()\n",
    "\n",
    "\n",
    "print ('Test sample wt_DR_nominal: ', len(predicttest__simple_D[test_target == 1]), '\\n',\n",
    "       '           tt_nominal:    ', len(predicttest__simple_D[test_target == 0]), '\\n',\n",
    "       '           total:         ', len(predicttest__simple_D))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "xlo, xhi, bins = float(Options['xlo']), float(Options['xhi']), int(Options['bins'])\n",
    "SignalName, BckgrdName = Options['SignalName'], Options['BackgroundName']\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(predicttest__simple_D[logical_and(test_target == 1, test_systematics == 0)], range=[xlo,xhi], bins=bins, histtype=\"step\", normed=0, label=SignalName+' norm')\n",
    "plt.hist(predicttest__simple_D[logical_and(test_target == 0, test_systematics == 0)], range=[xlo,xhi], bins=bins, histtype=\"step\", normed=0, label=BckgrdName+' norm')\n",
    "plt.hist(predicttest__simple_D[logical_and(test_target == 1, test_systematics == 1)], range=[xlo,xhi], bins=bins, histtype=\"step\", normed=0, label=SignalName+' syst', linestyle='dashed')\n",
    "plt.hist(predicttest__simple_D[logical_and(test_target == 0, test_systematics == 1)], range=[xlo,xhi], bins=bins, histtype=\"step\", normed=0, label=BckgrdName+' syst', linestyle='dashed')\n",
    "plt.ylim(0, plt.gca().get_ylim()[1] * float(Options['yScale']))\n",
    "plt.legend()\n",
    "plt.xlabel('Simple_D response', horizontalalignment='left', fontsize='large')\n",
    "plt.title('Absolute')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(predicttest__simple_D[logical_and(test_target == 1, test_systematics == 0)], range=[xlo,xhi], bins=bins, histtype=\"step\", normed=1, label=SignalName+' norm')\n",
    "plt.hist(predicttest__simple_D[logical_and(test_target == 0, test_systematics == 0)], range=[xlo,xhi], bins=bins, histtype=\"step\", normed=1, label=BckgrdName+' norm')\n",
    "plt.hist(predicttest__simple_D[logical_and(test_target == 1, test_systematics == 1)], range=[xlo,xhi], bins=bins, histtype=\"step\", normed=1, label=SignalName+' syst', linestyle='dashed')\n",
    "plt.hist(predicttest__simple_D[logical_and(test_target == 0, test_systematics == 1)], range=[xlo,xhi], bins=bins, histtype=\"step\", normed=1, label=BckgrdName+' syst', linestyle='dashed')\n",
    "plt.ylim(0, plt.gca().get_ylim()[1] * float(Options['yScale']))\n",
    "plt.legend()\n",
    "plt.xlabel('Simple_D response', horizontalalignment='left', fontsize='large')\n",
    "plt.title('Normalised')\n",
    "\n",
    "plt.show()\n",
    "plt.gcf().clear()\n",
    "\n",
    "\n",
    "print ('Test sample wt_DR_nominal: ', len(predicttest__simple_D[logical_and(test_target == 1, test_systematics == 0)]), '\\n',\n",
    "       '            wt_DS_nominal: ', len(predicttest__simple_D[logical_and(test_target == 1, test_systematics == 1)]), '\\n',\n",
    "       '               tt_nominal: ', len(predicttest__simple_D[logical_and(test_target == 0, test_systematics == 0)]), '\\n',\n",
    "       '           tt systematics: ', len(predicttest__simple_D[logical_and(test_target == 0, test_systematics == 1)])\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4. Adversarial networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 4.1 Build networks by Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "# 3 hiddend layers\n",
    "ANN_inputs = Input(shape=(train_event_transfered.shape[1],), name='Net_f_input')\n",
    "ANN_Dx = Dense(32, activation=\"relu\", name='Net_f_layer1')(ANN_inputs)\n",
    "ANN_Dx = Dense(32, activation=\"relu\", name='Net_f_layer2')(ANN_Dx)\n",
    "ANN_Dx = Dense(32, activation=\"relu\", name='Net_f_layer3')(ANN_Dx)\n",
    "ANN_Dx = Dense(1, activation=\"sigmoid\", name='Net_f_output')(ANN_Dx)\n",
    "ANN_D = Model(inputs=[ANN_inputs], outputs=[ANN_Dx], name='Net_f_model')\n",
    "\n",
    "# ANN_Rx = ANN_Dx\n",
    "ANN_Rx = ANN_D(ANN_inputs)\n",
    "ANN_Rx = Dense(32, activation=\"relu\", name='Net_r_layer1')(ANN_Rx)\n",
    "ANN_Rx = Dense(32, activation=\"relu\", name='Net_r_layer2')(ANN_Rx)\n",
    "ANN_Rx = Dense(32, activation=\"relu\", name='Net_r_layer3')(ANN_Rx)\n",
    "ANN_Rx = Dense(1, activation=\"sigmoid\", name='Net_r_output')(ANN_Rx)\n",
    "ANN_R = Model(inputs=[ANN_inputs], outputs=[ANN_Rx], name='Net_r_model')\n",
    "\n",
    "lam = -10  # control the trade-off between classification performance and independence\n",
    "\n",
    "def make_loss_ANN_D(c):\n",
    "    def loss_ANN_D(z_true, z_pred):\n",
    "        return c * K.binary_crossentropy(z_true, z_pred)\n",
    "    return loss_ANN_D\n",
    "\n",
    "def make_loss_ANN_R(c):\n",
    "    def loss_ANN_R(z_true, z_pred):\n",
    "        return c * K.binary_crossentropy(z_true, z_pred)\n",
    "    return loss_ANN_R\n",
    "\n",
    "def make_trainable(network, flag):\n",
    "    network.trainable = flag\n",
    "    network.compile\n",
    "    for l in network.layers:\n",
    "        l.trainable = flag\n",
    "\n",
    "opt_ANN_D = SGD()\n",
    "ANN_D.compile(loss=[make_loss_ANN_D(c=1.0)], optimizer=opt_ANN_D)\n",
    "# ANN_D.summary()\n",
    "plot_model(ANN_D, to_file='png/ANN_D.png')\n",
    "plot_model(ANN_R, to_file='png/ANN_R.png')\n",
    "\n",
    "opt_ANN_DRf = SGD(momentum=0.3)\n",
    "ANN_DRf = Model(inputs=[ANN_inputs], outputs=[ANN_D(ANN_inputs), ANN_R(ANN_inputs)])\n",
    "make_trainable(ANN_R, False)\n",
    "make_trainable(ANN_D, True)\n",
    "ANN_DRf.compile(loss=[make_loss_ANN_D(c=1.0), make_loss_ANN_R(c=lam)], optimizer=opt_ANN_DRf)\n",
    "plot_model(ANN_DRf, to_file='png/ANN_DRf.png')\n",
    "\n",
    "opt_ANN_DfR = SGD(momentum=0.2)\n",
    "ANN_DfR = Model(inputs=[ANN_inputs], outputs=[ANN_R(ANN_inputs)])\n",
    "make_trainable(ANN_R, True)\n",
    "make_trainable(ANN_D, False)\n",
    "ANN_DfR.compile(loss=[make_loss_ANN_R(c=1.0)], optimizer=opt_ANN_DfR)\n",
    "plot_model(ANN_DfR, to_file='png/ANN_DfR.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 4.2 Pretrain ANN_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "''' Pretraining of ANN_D on train_event_transfered with target train_target, using train_weight as EventWeight '''\n",
    "make_trainable(ANN_R, False)\n",
    "make_trainable(ANN_D, True)\n",
    "# ANN_D.compile(loss=ANN_D.loss, optimizer=ANN_D.optimizer)\n",
    "ANN_D.fit(train_event_transfered, train_target, sample_weight=train_weight, epochs=int(Options['PreTrainEpochs']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 4.3 ANN_D only results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# ''' Define a function to plot losses '''\n",
    "\n",
    "# from IPython import display\n",
    "\n",
    "# def plot_loss(i, loss):\n",
    "#     display.clear_output(wait=True)\n",
    "#     display.display(plt.gcf())\n",
    "\n",
    "#     ax1 = plt.subplot(311)   \n",
    "#     values = np.array(loss[\"L_D\"])\n",
    "#     print(values)\n",
    "#     plt.plot(range(len(values)), values, label=r\"$L_D$\", color=\"blue\")\n",
    "#     plt.legend(loc=\"upper right\")\n",
    "#     plt.grid()\n",
    "    \n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# loss = {\"L_D\": []}\n",
    "\n",
    "# for i in range(61):\n",
    "\n",
    "#     l = ANN_D.evaluate(test_event_transfered, test_target, sample_weight=test_weight, verbose=0)\n",
    "#     print(l)\n",
    "#     loss[\"L_D\"].append(l)\n",
    "#     plot_loss(i, loss)\n",
    "#     ANN_D.fit(train_event_transfered, train_target, sample_weight=train_weight, epochs=1, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 4.3.1 ANN_D only ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "''' Apply training results to test sample; and training sample for checking '''\n",
    "predicttrain__ANN_D = ANN_D.predict(train_event_transfered)\n",
    "predicttest__ANN_D = ANN_D.predict(test_event_transfered)\n",
    "\n",
    "''' Plot ROC and NN outpout '''\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print('Traing ROC: ', roc_auc_score(train_target, predicttrain__ANN_D))\n",
    "print('Test ROC:   ', roc_auc_score(test_target, predicttest__ANN_D))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "train__false_positive_rate, train__true_positive_rate, train__thresholds = roc_curve(train_target, predicttrain__ANN_D)\n",
    "test__false_positive_rate, test__true_positive_rate, test__thresholds = roc_curve(test_target, predicttest__ANN_D)\n",
    "train__roc_auc = auc(train__false_positive_rate, train__true_positive_rate)\n",
    "test__roc_auc = auc(test__false_positive_rate, test__true_positive_rate)\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(train__false_positive_rate, train__true_positive_rate, 'g--', label='Train AUC = %0.2f'% train__roc_auc)\n",
    "plt.plot(test__false_positive_rate, test__true_positive_rate, 'b', label='Test AUC = %0.2f'% test__roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.,1.])\n",
    "plt.ylim([-0.,1.])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "plt.gcf().clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 4.3.2 ANN_D only overtaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "xlo, xhi, bins = float(Options['xlo']), float(Options['xhi']), int(Options['bins'])\n",
    "SignalName, BckgrdName = Options['SignalName'], Options['BackgroundName']\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(predicttrain__ANN_D[train_target == 1], range=[xlo, xhi], bins=bins, histtype=\"step\", normed=0, label=SignalName+' training')\n",
    "plt.hist(predicttrain__ANN_D[train_target == 0], range=[xlo, xhi], bins=bins, histtype=\"step\", normed=0, label=BckgrdName+' training')\n",
    "plt.hist(predicttest__ANN_D[test_target == 1],   range=[xlo, xhi], bins=bins, histtype=\"step\", normed=0, label=SignalName+' test', linestyle='dashed')\n",
    "plt.hist(predicttest__ANN_D[test_target == 0],   range=[xlo, xhi], bins=bins, histtype=\"step\", normed=0, label=BckgrdName+' test', linestyle='dashed')\n",
    "plt.ylim(0, plt.gca().get_ylim()[1] * float(Options['yScale']))\n",
    "plt.legend()\n",
    "plt.xlabel('ANN_D response', horizontalalignment='left', fontsize='large')\n",
    "plt.title('Absolute')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(predicttrain__ANN_D[train_target == 1], range=[xlo, xhi], bins=bins, histtype=\"step\", normed=1, label=SignalName+' training')\n",
    "plt.hist(predicttrain__ANN_D[train_target == 0], range=[xlo, xhi], bins=bins, histtype=\"step\", normed=1, label=BckgrdName+' training')\n",
    "plt.hist(predicttest__ANN_D[test_target == 1],   range=[xlo, xhi], bins=bins, histtype=\"step\", normed=1, label=SignalName+' test', linestyle='dashed')\n",
    "plt.hist(predicttest__ANN_D[test_target == 0],   range=[xlo, xhi], bins=bins, histtype=\"step\", normed=1, label=BckgrdName+' test', linestyle='dashed')\n",
    "plt.ylim(0, plt.gca().get_ylim()[1] * float(Options['yScale']))\n",
    "plt.legend()\n",
    "plt.xlabel('ANN_D response', horizontalalignment='left', fontsize='large')\n",
    "plt.title('Normalised')\n",
    "\n",
    "plt.show()\n",
    "plt.gcf().clear()\n",
    "\n",
    "print ('Test sample wt_DR_nominal: ', len(predicttest__ANN_D[test_target == 1]), '\\n',\n",
    "       '           tt_nominal:    ', len(predicttest__ANN_D[test_target == 0]), '\\n',\n",
    "       '           total:         ', len(predicttest__ANN_D))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 4.3.3 ANN_D only syst deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "xlo, xhi, bins = float(Options['xlo']), float(Options['xhi']), int(Options['bins'])\n",
    "SignalName, BckgrdName = Options['SignalName'], Options['BackgroundName']\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(predicttest__ANN_D[logical_and(test_target == 1, test_systematics == 0)], range=[xlo, xhi], bins=bins, histtype=\"step\", normed=0, label=SignalName+' norm')\n",
    "plt.hist(predicttest__ANN_D[logical_and(test_target == 0, test_systematics == 0)], range=[xlo, xhi], bins=bins, histtype=\"step\", normed=0, label=BckgrdName+' norm')\n",
    "plt.hist(predicttest__ANN_D[logical_and(test_target == 1, test_systematics == 1)], range=[xlo, xhi], bins=bins, histtype=\"step\", normed=0, label=SignalName+' syst', linestyle='dashed', )\n",
    "plt.hist(predicttest__ANN_D[logical_and(test_target == 0, test_systematics == 1)], range=[xlo, xhi], bins=bins, histtype=\"step\", normed=0, label=BckgrdName+' syst'\n",
    "         , linestyle='dashed', )\n",
    "plt.ylim(0, plt.gca().get_ylim()[1] * float(Options['yScale']))\n",
    "plt.legend()\n",
    "plt.xlabel('ANN_D response', horizontalalignment='left', fontsize='large')\n",
    "plt.title('Absolute')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(predicttest__ANN_D[logical_and(test_target == 1, test_systematics == 0)], range=[xlo, xhi], bins=bins, histtype=\"step\", normed=1, label=SignalName+' norm')\n",
    "plt.hist(predicttest__ANN_D[logical_and(test_target == 0, test_systematics == 0)], range=[xlo, xhi], bins=bins, histtype=\"step\", normed=1, label=BckgrdName+' norm')\n",
    "plt.hist(predicttest__ANN_D[logical_and(test_target == 1, test_systematics == 1)], range=[xlo, xhi], bins=bins, histtype=\"step\", normed=1, label=SignalName+' syst', linestyle='dashed', )\n",
    "plt.hist(predicttest__ANN_D[logical_and(test_target == 0, test_systematics == 1)], range=[xlo, xhi], bins=bins, histtype=\"step\", normed=1, label=BckgrdName+' syst', linestyle='dashed', )\n",
    "plt.ylim(0, plt.gca().get_ylim()[1] * float(Options['yScale']))\n",
    "plt.legend()\n",
    "plt.xlabel('ANN_D response', horizontalalignment='left', fontsize='large')\n",
    "plt.title('Normalised')\n",
    "\n",
    "plt.show()\n",
    "plt.gcf().clear()\n",
    "\n",
    "print ('Test sample wt_DR_nominal: ', len(predicttest__ANN_D[logical_and(test_target == 1, test_systematics == 0)]), '\\n',\n",
    "       '            wt_DS_nominal: ', len(predicttest__ANN_D[logical_and(test_target == 1, test_systematics == 1)]), '\\n',\n",
    "       '               tt_nominal: ', len(predicttest__ANN_D[logical_and(test_target == 0, test_systematics == 0)]), '\\n',\n",
    "       '           tt systematics: ', len(predicttest__ANN_D[logical_and(test_target == 0, test_systematics == 1)])\n",
    "      )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 4.4 Pretrain ANN_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "''' Pretraining of ANN_R on train_event_transfered with target train_systematics, using train_weight as EventWeight '''\n",
    "make_trainable(ANN_R, True)\n",
    "make_trainable(ANN_D, False)\n",
    "# ANN_DfR.compile(loss=ANN_DfR.loss, optimizer=ANN_DfR.optimizer)\n",
    "ANN_DfR.fit(train_event_transfered, train_systematics, sample_weight=train_weight, epochs=int(Options['PreTrainEpochs']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 4.5 Train adversarial networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "''' Define a function to plot losses '''\n",
    "\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_losses(i, losses):\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "\n",
    "    ax1 = plt.subplot(311)   \n",
    "    values = np.array(losses[\"L_f\"])\n",
    "    plt.plot(range(len(values)), values, label=r\"$loss_D$\", color=\"blue\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid()\n",
    "    \n",
    "    ax2 = plt.subplot(312, sharex=ax1) \n",
    "    values = np.array(losses[\"L_r\"]) / lam\n",
    "    plt.plot(range(len(values)), values, label=r\"$loss_R$\", color=\"green\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid()\n",
    "    \n",
    "    ax3 = plt.subplot(313, sharex=ax1)\n",
    "    values = np.array(losses[\"L_f - L_r\"])\n",
    "    plt.plot(range(len(values)), values, label=r\"$loss_D \"+str(lam)+r\"*loss_R$\", color=\"red\")  \n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 4.5.1 Adversarial networks losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# ReadFiles()\n",
    "\n",
    "losses = {\"L_f\": [], \"L_r\": [], \"L_f - L_r\": []}\n",
    "ANN_DRf.metrics_names\n",
    "\n",
    "batch_size = 128\n",
    "for i in range(int(Options['Iterations'])):\n",
    "# for i in range(2):\n",
    "\n",
    "    l = ANN_DRf.evaluate(test_event_transfered, [test_target, test_systematics], sample_weight=[test_weight, test_weight], verbose=0)    #TODO\n",
    "    losses[\"L_f\"].append(l[1][None][0])\n",
    "    losses[\"L_r\"].append(l[2][None][0])\n",
    "    losses[\"L_f - L_r\"].append(l[0][None][0])\n",
    "    print('zhangrui', losses[\"L_f\"][-1], losses[\"L_r\"][-1]/lam, '*', lam, losses[\"L_f - L_r\"][-1])\n",
    "    \n",
    "    if i % 5 == 0:\n",
    "        plot_losses(i, losses)\n",
    "\n",
    "    # Fit ANN_D\n",
    "    ''' Problem with train_on_batch is EventWeight does not shuffle with events\n",
    "        Memory can handle all events training\n",
    "        - need to check epochs '''\n",
    "    make_trainable(ANN_R, False)\n",
    "    make_trainable(ANN_D, True)\n",
    "\n",
    "    indices = np.random.permutation(len(train_event_transfered))[1:]\n",
    "    if i % 3 == 0:\n",
    "        ANN_DRf.fit(train_event_transfered[indices], [train_target[indices], train_systematics[indices]], sample_weight=[train_weight[indices], train_weight[indices]], \n",
    "                epochs=int(Options['AdTrainEpochs']), verbose=1)\n",
    "    else:\n",
    "        ANN_DRf.train_on_batch(train_event_transfered[indices], [train_target[indices], train_systematics[indices]], sample_weight=[train_weight[indices], train_weight[indices]])\n",
    "\n",
    "        #     ANN_DRf.fit(train_event_transfered, [train_target, train_systematics], sample_weight=[train_weight, train_weight], \n",
    "#                 epochs=int(Options['AdTrainEpochs']), verbose=1)\n",
    "\n",
    "\n",
    "    # Fit ANN_R\n",
    "    make_trainable(ANN_R, True)\n",
    "    make_trainable(ANN_D, False)\n",
    "#     ANN_DfR.compile(loss=ANN_DfR.loss, optimizer=ANN_DfR.optimizer)\n",
    "#     ANN_DfR.train_on_batch(train_event_transfered, train_systematics, sample_weight=train_weight)\n",
    "    ANN_DfR.fit(train_event_transfered, train_systematics, sample_weight=train_weight, batch_size=batch_size, epochs=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 4.5.2 Save model to disk\n",
    "https://stackoverflow.com/questions/29788047/keep-tfidf-result-for-predicting-new-content-using-scikit-for-python\n",
    "- If you want to store features list for testing data for use in future, you can do this:\n",
    "      tfidf = transformer.fit_transform(vectorizer.fit_transform(corpus))\n",
    "\n",
    "- store the content.\n",
    "      with open(\"x_result.pkl\", 'wb') as handle:\n",
    "          pickle.dump(tfidf, handle)\n",
    "- load the content\n",
    "      tfidf = pickle.load(open(\"x_result.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "outfolder = 'results/' + Options['Output'] + '/'\n",
    "os.mkdir(outfolder)\n",
    "# serialize model to JSON\n",
    "model_json = ANN_D.to_json()\n",
    "with open(outfolder + Options['Adresult'] + \".json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "ANN_D.save_weights(outfolder + Options['Adresult'] + \".h5\")\n",
    "print(\"Saved \"+ outfolder + Options['Adresult'] + \" to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.3 Adversarial networks ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "predicttest__ANN = ANN_D.predict(test_event_transfered)\n",
    "predicttrain__ANN = ANN_D.predict(train_event_transfered)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "print('Traing ROC: ', roc_auc_score(train_target, predicttrain__ANN))\n",
    "print('Test ROC:   ', roc_auc_score(test_target, predicttest__ANN))\n",
    "\n",
    "\n",
    "train__false_positive_rate, train__true_positive_rate, train__thresholds = roc_curve(train_target, predicttrain__ANN)\n",
    "test__false_positive_rate, test__true_positive_rate, test__thresholds = roc_curve(test_target, predicttest__ANN)\n",
    "train__roc_auc = auc(train__false_positive_rate, train__true_positive_rate)\n",
    "test__roc_auc = auc(test__false_positive_rate, test__true_positive_rate)\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(train__false_positive_rate, train__true_positive_rate, 'g--', label='train AUC = %0.2f'% train__roc_auc)\n",
    "plt.plot(test__false_positive_rate, test__true_positive_rate, 'b', label='test AUC = %0.2f'% test__roc_auc)\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.,1.])\n",
    "plt.ylim([-0.,1.])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 4.5.4 Adversarial networks overtaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "xlo, xhi, bins = float(Options['xlo']), float(Options['xhi']), int(Options['bins'])\n",
    "SignalName, BckgrdName = Options['SignalName'], Options['BackgroundName']\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(predicttrain__ANN[train_target == 1], range=[xlo, xhi], bins=bins, histtype=\"step\", normed=0, label=SignalName+' training')\n",
    "plt.hist(predicttrain__ANN[train_target == 0], range=[xlo, xhi], bins=bins, histtype=\"step\", normed=0, label=BckgrdName+' training')\n",
    "plt.hist(predicttest__ANN[test_target == 1],   range=[xlo, xhi], bins=bins, histtype=\"step\", normed=0, label=SignalName+' test', linestyle='dashed')\n",
    "plt.hist(predicttest__ANN[test_target == 0],   range=[xlo, xhi], bins=bins, histtype=\"step\", normed=0, label=BckgrdName+' test', linestyle='dashed')\n",
    "plt.ylim(0, plt.gca().get_ylim()[1] * float(Options['yScale']))\n",
    "plt.legend()\n",
    "plt.xlabel('ANN response', horizontalalignment='left', fontsize='large')\n",
    "plt.title('Absolute')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(predicttrain__ANN[train_target == 1], range=[xlo, xhi], bins=bins, histtype=\"step\", normed=1, label=SignalName+' training')\n",
    "plt.hist(predicttrain__ANN[train_target == 0], range=[xlo, xhi], bins=bins, histtype=\"step\", normed=1, label=BckgrdName+' training')\n",
    "plt.hist(predicttest__ANN[test_target == 1],   range=[xlo, xhi], bins=bins, histtype=\"step\", normed=1, label=SignalName+' test', linestyle='dashed')\n",
    "plt.hist(predicttest__ANN[test_target == 0],   range=[xlo, xhi], bins=bins, histtype=\"step\", normed=1, label=BckgrdName+' test', linestyle='dashed')\n",
    "plt.ylim(0, plt.gca().get_ylim()[1] * float(Options['yScale']))\n",
    "plt.legend()\n",
    "plt.xlabel('ANN response', horizontalalignment='left', fontsize='large')\n",
    "plt.title('Normalised')\n",
    "\n",
    "plt.show()\n",
    "plt.gcf().clear()\n",
    "\n",
    "print ('Test sample wt_nominal: ', len(predicttest__ANN[test_target == 1]), '\\n',\n",
    "       '           tt_nominal: ', len(predicttest__ANN[test_target == 0]), '\\n',\n",
    "       '           total:     ', len(predicttest__ANN))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 4.5.5 Adversarial networks syst deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "xlo, xhi, bins = float(Options['xlo']), float(Options['xhi']), int(Options['bins'])\n",
    "SignalName, BckgrdName = Options['SignalName'], Options['BackgroundName']\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(predicttest__ANN[logical_and(test_target == 1, test_systematics == 0)], range=[xlo, xhi], bins=bins, histtype=\"step\", normed=0, label=SignalName+' norm')\n",
    "plt.hist(predicttest__ANN[logical_and(test_target == 0, test_systematics == 0)], range=[xlo, xhi], bins=bins, histtype=\"step\", normed=0, label=BckgrdName+' norm')\n",
    "plt.hist(predicttest__ANN[logical_and(test_target == 1, test_systematics == 1)], range=[xlo, xhi], bins=bins, histtype=\"step\", normed=0, label=SignalName+' syst', linestyle='dashed')\n",
    "plt.hist(predicttest__ANN[logical_and(test_target == 0, test_systematics == 1)], range=[xlo, xhi], bins=bins, histtype=\"step\", normed=0, label=BckgrdName+' syst', linestyle='dashed')\n",
    "plt.ylim(0, plt.gca().get_ylim()[1] * float(Options['yScale']))\n",
    "plt.legend()\n",
    "plt.xlabel('ANN response', horizontalalignment='left', fontsize='large')\n",
    "plt.title('Absolute')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(predicttest__ANN[logical_and(test_target == 1, test_systematics == 0)], range=[xlo, xhi], bins=bins, histtype=\"step\", normed=1, label=SignalName+' norm')\n",
    "plt.hist(predicttest__ANN[logical_and(test_target == 0, test_systematics == 0)], range=[xlo, xhi], bins=bins, histtype=\"step\", normed=1, label=BckgrdName+' norm')\n",
    "plt.hist(predicttest__ANN[logical_and(test_target == 1, test_systematics == 1)], range=[xlo, xhi], bins=bins, histtype=\"step\", normed=1, label=SignalName+' syst', linestyle='dashed')\n",
    "plt.hist(predicttest__ANN[logical_and(test_target == 0, test_systematics == 1)], range=[xlo, xhi], bins=bins, histtype=\"step\", normed=1, label=BckgrdName+' syst', linestyle='dashed')\n",
    "plt.ylim(0, plt.gca().get_ylim()[1] * float(Options['yScale']))\n",
    "plt.legend()\n",
    "plt.xlabel('ANN response', horizontalalignment='left', fontsize='large')\n",
    "plt.title('Normalised')\n",
    "\n",
    "plt.show()\n",
    "plt.gcf().clear()\n",
    "\n",
    "print ('Test sample wt_DR_nominal: ', len(predicttest__ANN[logical_and(test_target == 1, test_systematics == 0)]), '\\n',\n",
    "       '            wt_DS_nominal: ', len(predicttest__ANN[logical_and(test_target == 1, test_systematics == 1)]), '\\n',\n",
    "       '               tt_nominal: ', len(predicttest__ANN[logical_and(test_target == 0, test_systematics == 0)]), '\\n',\n",
    "       '           tt systematics: ', len(predicttest__ANN[logical_and(test_target == 0, test_systematics == 1)])\n",
    "      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
